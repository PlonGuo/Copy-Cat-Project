# Copy-Cat-Project

Copy-cat Bot

Data Set: 
Speeches, texts, and interviews of Steve Jobs

Project idea: 
We would like to generate plausible new texts which look like the texts or speeches of Steve Jobs

The approach we will use: 
We'll start by gathering a comprehensive dataset comprising transcripts of Steve Jobs' speeches, interviews, writings, and product launches.  We may use LSTM or GPT architectures to train our model on the prepared sequences. These models are adept at capturing long-term dependencies and nuances in sequential data, making them apt for text generation tasks. After training, we will use the model to generate new text passages with Job’s style. The output might require fine-tuning after generation of text passages. Finally, we will design or refer to some standard to evaluate the quality of generated text.

Software we will use: Jupyter notebook, Google colab, ChatGPT, TensorFlow/Pytorch, Hugging Face Transformers, NLTK/spaCy, Scikit-learn, Pandas, Matplotlib and Seaborn, Git/GitHub, 

References: 
“ProbabilisticMachine Learning" byKevin P. Murphy, 2023.
"Natural Language Processing in Action" by Lane, Howard, and Hapke
"Speech and Language Processing" by Daniel Jurafsky and James H. Martin
"Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow" by Aurélien Géron
Scikit-Learn Documentation

Teammates: Jason Guo, Joey Jiang

Timeline: 
Week 6:
Data Collection: Gather transcripts of Steve Jobs' speeches, interviews, and book excerpts.
Preliminary Data Analysis: Understand the volume and characteristics of the data.
Detail the project's objectives, methodology, and expected outcomes.

Week 7:
Data Preprocessing: Clean, tokenize, and format the data for modeling.
Initial Model Exploration: Research the structure of chosen models.


Week 8:
Model Implementation: Begin constructing the model using a deep learning framework.
Model Training: Start fine-tuning the model with a subset of the data.
Initial Model Evaluation: Assess the preliminary performance of the model.

Week 9:
Full Model Training: Complete the fine-tuning using all collected data.
Model Refinement: Adjust and optimize the model based on evaluation metrics.
Design Interface (if deploying): Begin interface design for model deployment.

Week 10:
Model Integration: Integrate the model into a web application or API.
Internal Testing: Test the model and application internally within the team.
Prepare Presentation: Highlight objectives, methodology, results, and demo if applicable.

Week 11:
Gather Feedback: Collect feedback on the model's generated content.
Final Model Optimization: Refine the model based on received feedback.
Draft Final Report: Compile the project summary, learned experiences, results, and documentations for submission.


